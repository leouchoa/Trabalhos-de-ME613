---
title: Teste 07
author: Grupo 03
output: html_document
---

```{r preliminares, include=F}
hd = c("ID", "County", "State", "Land_Area", "Total_Pop", "Pct_18_34", "Pct_65Plus", "num_Phys", "num_Beds", "Total_Crimes", "Pct_HSG", "Pct_Bdgree", "Pct_Below_Poverty_Level", "Pct_Unemployment", "PCI", "Total_Person_Inc", "Geographic_Region")

CDI = read.table(file = "/home/leouchoa/Documents/papers/2016-1/regressao/codes/teste07/APPENC02.txt", header=F, col.names = hd)

#CDI = read.table(file = "http://www.stat.ufl.edu/~rrandles/sta4210/Rclassnotes/data/textdatasets/KutnerData/Appendix%20C%20Data%20Sets/APPENC02.txt", header=F, col.names = hd)

attach(CDI)

vetor.ex143 = data.frame(Total_Pop, num_Beds, Total_Person_Inc)
modelo.ex143 = vector("list", length(vetor.ex143))
betas.ex143 = matrix(nrow = length(modelo.ex143), ncol = 2)
mse.ex143 = rep(0,length(modelo.ex143))

for(i in 1:length(modelo.ex143)){
  modelo.ex143[[i]] = lm(num_Phys ~ data.matrix(vetor.ex143[i]))
  betas.ex143[i,] = coef(modelo.ex143[[i]])
  mse.ex143[i] = summary(modelo.ex143[[i]])$sigma^2
}

```


#Exercício 4.26

Este conjunto de exercícios é referente ao banco de dados "CDI" utilizado em exercícios anteriores. Aqui, voltamos nossa atenção à regressão do número de médicos ativos utilizando a variável "total da população" como preditora.

##Item a

Devemos construir um intervalo conjunto de Bonferroni para ambos $\beta_{0}$ e $\beta_{1}$. Utilizando a resolução do exercício 1.43, teste 05, temos 

```{r betas}
betas.ex143
```

Lembre-se que o intervalo -conservativo- conjunto dado pela desigualdade de Bonferroni é $$\hat{\beta_{i}} \pm t_{n-2;alpha/4}\sqrt{\widehat{V(\widehat{\beta_{i}})}}.$$ Logo, o código a seguir nos permite obter os intervalos para os intercepto e coeficiente angular, respectivamente.

```{r IC_Bonf_alg}
m = length(betas.ex143[1,])
alfa = 0.05

IC.bonf = matrix(nrow = m, ncol = 2)
colnames(IC.bonf) = c("Lower Bound", "Upper Bound")
rownames(IC.bonf) = c("Intercept", "Slope")

for (i in 1:m)
  IC.bonf[i,] = betas.ex143[1,i] + c(-1,1)*summary(modelo.ex143[[1]])$coef[i,2]*qt(1-alfa/(2*m), 
                        df = summary(modelo.ex143[[1]])$df[2])

```

Que são

```{r IC_Bonf_val, echo=F}
round(IC.bonf, digits=6)
```

##Item b

Neste item, é sugerido que $\beta_{0} = -100$ e $\beta_{1} = 0.0028$. Ao observar os limites construidos em a), podemos concluir que o intervalo suporta sim esta proposta, pois -100 está entre $[`r IC.bonf[1,] `]$ e 0.0028 está entre $[`r IC.bonf[2,] `]$.

#itens c-d

Gostariamos de estimar o número esperado de médicos para condados de tamanho de tamanhos 500, 1000 e 5000, ou seja, é um problema de predição. Para uma boa estimação, criamos intervalos de confiança para os 3 estimadores pontuais das médias das distribuições. Entretanto, para construir estes intervalos, temos dois possíveis procedimentos, sendo eles Bonferroni e Working-Hotelling. Assim, vamos primeiro avaliar cada método, escolher o mais eficaz e só então construir o intervalo para o resposta média para cada condado.

Primeiramente, note que os métodos são bem parecidos 

1. Bonferroni
 $$\hat{Y_h} \pm B\sqrt{\widehat{V(\widehat{Y_h})}}$$
 
    onde $$B = t(n-2;alpha/(2g))$$

2. Working-Hotelling
 $$\hat{Y_h} \pm W\sqrt{\widehat{V(\widehat{Y_h})}}$$

    onde $$W^2 = gF(1-alpha;g , n - 2)$$ $g$ é o número de estimadores pontuais para os quais queremos criar o intervalo conjunto e a variância do estimador de predição de média, $\hat{Y_h}$ é $$V(\hat{Y_h}) = \sqrt{MSE} \sqrt{\frac{1}{n} + \frac{( X_h - \hat{X})^2}{S_{xx}}}$$.

Desta forma, para obtermos o melhor intervalo basta comparar os quantís W e B e ver qual é o menor, pois a única diferença entre as duas técnicas é o quantil. Segue o algorítmo que obtém estes valores.

```{r comp_w-b}
alfa=.1
g=3
(B = qt(1-alfa/(2*g) ,df=summary(modelo.ex143[[1]])$df[2]))
(W = sqrt(g*qf(1-alfa ,g ,summary(modelo.ex143[[1]])$df[2])))
```

Como `r B` é menor `r W`, concluimos que o intervalo de Bonferroni é melhor. Assim, vamos construir um intervalo para cada nível de condado onde a população total satisfaz a condição pedida.

Antes de calcular o diretamente intervalo vamos calcular, por partes, as predições e as variâncias dos estimadores pontuais das médias. Primeiramente as predições, como segue abaixo

```{r predicoes}
X_h = c(500,1000,5000)
beta.ex426 = lm(num_Phys ~ Total_Pop)
y.hat = rep(0,length(X_h))
for (i in 1:length(X_h)){
  y.hat[i] = beta.ex426$coefficients[[1]] + beta.ex426$coefficients[[2]]*X_h[i]
}
y.hat
```

Agora as variâncias 

```{r var_pred}
n=nrow(CDI)
v_y.hat = rep(0,length=length(X_h))
MSE2 = summary(beta.ex426)$sigma
Sxx  = sum((Total_Pop - mean(Total_Pop))^2)
for (i in 1:length(X_h)) {
  v_y.hat[i] = MSE2*sqrt((1/n + (X_h[i]-mean(Total_Pop))^2/Sxx))
}
v_y.hat
```

E por fim os intervalos

```{r intervalos}
IC.ex426c = matrix(nrow = length(X_h),ncol = 2)
rownames(IC.ex426c) = c("X_1","X_2","X_3")
colnames(IC.ex426c) = c("lower","upper")
for (i in 1:length(X_h)) {
  IC.ex426c[i,] = y.hat[i] + c(-1,1)*B*v_y.hat[i]
}
IC.ex426c
```

#Exercício 6.28

##Item a

Ao fazer o gráfico de ramo e folha para cada variável preditora (utilizando escala 20, para termos maior precisão), podemos perceber que a população está fragmentada em cidades de areás menores, enquanto que nas maiores áreas não há tanta concentração, ou seja, este é um pais não muito povoado. Os fatos que suportam esta ideia são as grandes concentrações de massa nos "topos"/inicios de todos gráficos, exceto para a variável "área do território", que parece estar relativamente despersa ao longo dos níveis.


##Item b
O gráfico de matriz de dispersão e a matriz de correlação são dados a seguir.

```{r matriz_disp}
modelo.ex628 = vector("list", length = 2)
dens_Pop = Total_Pop/Land_Area

modelo.ex628[[1]] = lm(num_Phys ~ Total_Pop + Land_Area + Total_Person_Inc)
modelo.ex628[[2]] = lm(num_Phys ~ dens_Pop + Pct_65Plus + Total_Person_Inc)

par(pty="s")
par(mfrow = c(2,3))
plot(x = Total_Pop, y = num_Phys, xlab = "Populacao Total" , ylab = "Numero de Medicos")
plot(Land_Area,num_Phys, xlab = "Area", ylab = "Numero de Medicos")
plot(Total_Person_Inc,num_Phys, xlab = "Renda Per Capita", ylab = "Numero de Medicos")
plot(dens_Pop,num_Phys, xlab = "Densidade Populacional", ylab = "Numero de Medicos")
plot(Pct_65Plus,num_Phys, xlab = "Percentagem Populacao Acima de 65 Anos", ylab = "Numero de Medicos")
plot(Pct_65Plus,num_Phys, xlab = "Percentagem Populacao Acima de 65 Anos", ylab = "Numero de Medicos")

summary(modelo.ex628[[1]], correlation = TRUE, digits = 4)$correlation
summary(modelo.ex628[[2]], correlation = TRUE, digits = 4)$correlation
```

Ao visualizar a matriz dispersão podemos ver que há uma correlação bem alta entre o número de médicos e renda per capita, população total, enquanto que para o resto das variáveis a correlação é relativamente baixa. Partindo para a matriz de correlação podemos observar, para o modelo 1, que os coeficientes $\beta_1$ e $\beta_4$ têm correlação alta entre si (de `r summary(modelo.ex628[[2]], correlation = TRUE, digits = 4)$correlation[2,4]`), enquanto o resto é bastante variado, mas baixo. 

Já para o modelo 2, os únicos coeficientes que têm correlação alta ( de `r summary(modelo.ex628[[2]], correlation = TRUE, digits = 4)$correlation[1,3]`) entre si são $\beta_0$ e $\beta_2$, ao passo que os outros ficam em torno de -0.03 -exceto $\beta_3$ e $\beta_4$.

FALTA ENROLAR MAIS UM POUCO

##itens c-d

Neste exercício, devemos ajustar um modelo de regressão de múltiplo de primeira ordem $$Y_i = \sum_{i=0}^{k}X_i \beta_i + \epsilon_i$$ cuja função de regressão será $$E\{Y_i\} = \sum_{i=0}^{k}X_i \beta_i$$ onde $X_0 = 1$ e $k=3$. O código que realiza a regressão para os modelo1 e modelo2 propostos seguem abaixo.

```{r models_reg}
modelo1 = lm(num_Phys ~ Total_Pop + Land_Area + Total_Person_Inc)
modelo2 = lm(num_Phys ~ Total_Pop/Land_Area + Pct_65Plus + Total_Person_Inc)
```

Adicionalmente, gostariamos de utilizar o $R^2$ múltiplo para ter uma palpite inicial de qual seria o melhor modelo ajustado pela reta de regressão de multipla de primeira ordem. Estes valores para cada modelo são dados a seguir. Note que eles são muito próximos logo, para este exemplo, o $R^2$ múltiplo não nos permite tirar qualquer conclusão.

```{r R2}
(summary(modelo1)$r.squared)
(summary(modelo2)$r.squared)
```

##item e
Para este, basta utilizar "plot(modelo.ex143[[i]], which = c(j,k))", caso outra pessoal, além de mim, que vá resolver nao perca tempo


#Exercício 6.29
##itens a-b

Para este exercício, usaremos o conjunto de dados CDI para entender como os números de crimes graves, densidade populacional, ganho pessoal per capita e porcentagem de graduados com ensino médio se relacionam em cada região geográfica. Em especial, faremos uma regressão do número de crimes graves contra as outras variáveis, ou seja, tentaremos explicar o comportamento de Y(número de crimes graves) utilizando $X_1$(densidade populacional), $X_2$(ganho pessoal per capita) e $X_3$(porcentagem de graduados com ensino médio). O modelo proposto para isto será $$Y_i = \sum_{i=0}^{k}X_i \beta_i + \epsilon_i$$ cuja função de regressão é $$E\{Y_i\} = \sum_{i=0}^{k}X_i \beta_i$$ onde $X_0 = 1$ e $k=3$. Para este modelo e, para cada um das 4 regiões geográficas (i=4), a técnica de regressão utilizada é dada pelo código abaixo.


```{r reg.ex629}
modelo1.ex629 = vector("list",max(Geographic_Region))
beta.ex629 = matrix(0,nrow=max(Geographic_Region),ncol=4)
colnames(beta.ex629) = c("beta0","beta1","beta2","beta3")
rownames(beta.ex629) = c("regiao1","regiao2","regiao3","regiao4")
Dens=Total_Pop/Land_Area 

for(i in 1:max(Geographic_Region)){
  modelo1.ex629[[i]] = lm(Total_Crimes[which(Geographic_Region ==i)] ~ Dens[which(Geographic_Region==i)] +  Total_Person_Inc[which(Geographic_Region ==i)] + Pct_HSG[which(Geographic_Region==i)])
  beta.ex629[i,] = coef(modelo1.ex629[[i]])
}
(round(beta.ex629,digits = 3))
```
Portanto, as funções estimadas $\hat{Y_i}$ são 

1. $\hat{{Y_1}_i}$ = -26139.09 + 16.336${X_1}_i$ + 0.383${X_2}_i$ + 291.068${X_3}_i$
2. $\hat{{Y_2}_i}$ =  63104.12 + 2.588${X_1}_i$ + 3.602${X_2}_i$ - 854.549${X_3}_i$
3. $\hat{{Y_3}_i}$ =  56929.39 + 0.306${X_1}_i$ + 4.896${X_2}_i$ - 800.396${X_3}_i$
4. $\hat{{Y_4}_i}$ =  37724.58 - 0.992${X_1}_i$ + 3.627${X_2}_i$ - 489.015${X_3}_i$

Logo, podemos concluir que as únicas funções parecidas nos parâmetros são as funções 2 e 3.

##item c

Os valors dos $R^2$ e MSE para cada região geográfica são dados a seguir.

```{r r2 e MSE}
r2 = rep(0,times=max(Geographic_Region))
MSE.ex629 = rep(0,times=max(Geographic_Region))

for(i in 1:max(Geographic_Region)){
  r2[i] = summary(modelo1.ex629[[i]])$r.squared
  MSE.ex629[i] = summary(modelo1.ex629[[i]])$sigma^2
}
```

```{r echo=F}
tralala = round(rbind(r2,MSE.ex629), digits=2)
colnames(tralala) = c("regiao1","regiao2","regiao3","regiao4")
tralala
```


Ao ver os resultados de $R^2$ e $MSE$ por região podemos ver que os valores de $R^2$ estão altos mas não tão próximos, ao passo que, para os $MSE$, podemos notar uma grande variância. Portanto, podemos concluir que as similaridades entre regiões, para estes aspectos, só são preservadas para algumas regiões específicas nos valores de $R^2$.

##item d

Ao fazermos os boxplots dos resíduos de cada região, podemos notar que 


```{r boxplots_out}
boxplot(modelo1.ex629[[1]]$residuals,modelo1.ex629[[2]]$residuals,modelo1.ex629[[3]]$residuals,modelo1.ex629[[1]]$residuals, range=5, names=c("regiao 1","regiao 2","regiao 3","regiao 4"))
```

Para todas as regiões, podemos ver que há uma grande concentração de massa em torno do zero. Além disso, ao observarmos os valores máximos e mínimos de cada gráfico, para a escala atual, percebemos que a dispersão do resíduo é relativamente similar entre as regiões. Por fim, o ponto mais claro é a questão dos outliers, sendo bem visível para os boxplots 1 e 4 (os casos 2 e 3 são discutíveis).

FALTA ENROLAR MAIS UM POUCO